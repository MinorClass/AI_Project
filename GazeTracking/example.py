import cv2
import mediapipe as mp
from gaze_tracking import GazeTracking
import time
import math 

gaze = GazeTracking()
# NOTE: I
webcam = cv2.VideoCapture(4) 

# MediaPipe Solutions API ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

# ë–¨ë¦¼ ê°ì§€ë¥¼ ìœ„í•œ ì „ì—­ ì„¤ì •
MAX_HISTORY_FRAMES = 30  # ë–¨ë¦¼ íŒë‹¨ì„ ìœ„í•´ ì¶”ì í•  í”„ë ˆì„ ìˆ˜
TREMOR_THRESHOLD = 0.3 # ë–¨ë¦¼ íŒë‹¨ ê¸°ì¤€ (ì¢Œí‘œ í‘œì¤€ í¸ì°¨ ê¸°ì¤€, ì¡°ì • ê°€ëŠ¥) - ë¯¼ê°ë„ë¥¼ ë” ë‚®ì¶”ê¸° ìœ„í•´ ê°’ì„ ë†’ì„
nose_history = [] # ì½” ëœë“œë§ˆí¬ ì¢Œí‘œ ì´ë ¥ ì €ì¥ (Normalized X, Y)
tremor_status = "(Stable)" # í˜„ì¬ ë–¨ë¦¼ ìƒíƒœ ë©”ì‹œì§€
# ----------------------------------------------------

gaze_start_time = None
is_gaze_outside_center = False
ALERT_THRESHOLD = 3.0

def calculate_tremor(x_history, y_history):
    """ì£¼ì–´ì§„ ì¢Œí‘œ ì´ë ¥ì˜ í‘œì¤€ í¸ì°¨ë¥¼ ê³„ì‚°í•˜ì—¬ ë–¨ë¦¼ ì •ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if len(x_history) < MAX_HISTORY_FRAMES:
        return 0.0 # ì´ë ¥ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ 0 ë°˜í™˜
    
    # í‰ê·  ê³„ì‚°
    mean_x = sum(x_history) / MAX_HISTORY_FRAMES 
    mean_y = sum(y_history) / MAX_HISTORY_FRAMES
    
    # ë¶„ì‚° ê³„ì‚°: (ì¢Œí‘œ - í‰ê· )^2ì˜ í•©
    variance_x = sum([(x - mean_x) ** 2 for x in x_history]) / MAX_HISTORY_FRAMES
    variance_y = sum([(y - mean_y) ** 2 for y in x_history]) / MAX_HISTORY_FRAMES # <-- ìˆ˜ì •: y_historyë¡œ ìˆ˜ì •í•´ì•¼ í•¨
    
    # í‘œì¤€ í¸ì°¨ ê³„ì‚° (ë£¨íŠ¸ ë¶„ì‚°)
    std_dev_x = math.sqrt(variance_x)
    std_dev_y = math.sqrt(variance_y)
    
    # Xì™€ Y í‘œì¤€ í¸ì°¨ì˜ í•©ì„ ë–¨ë¦¼ ì§€ìˆ˜ë¡œ ì‚¬ìš©
    return std_dev_x + std_dev_y

# -------------------------

LANDMARK_SPEC = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)
CONNECTION_SPEC = mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)

with mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1, 
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as pose:

    while True:
        ret, frame = webcam.read()
        if not ret:
            break
        gaze.refresh(frame)

        frame = gaze.annotated_frame()
        text = ""
        
        current_time = time.time()
        elapsed_time = 0.0
        
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ------------------- ê°ì§€ ì‹¤í–‰ (ë™ê¸° ë°©ì‹) -------------------
        results = pose.process(rgb_frame)
        
        # ë–¨ë¦¼ ê°ì§€ ë° ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° ì´ˆê¸°í™”
        current_tremor_score = 0.0
        
        if results.pose_landmarks:
            # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            mp_drawing.draw_landmarks(
                frame, 
                results.pose_landmarks, 
                mp_pose.POSE_CONNECTIONS,
                LANDMARK_SPEC,
                CONNECTION_SPEC
            )
            
            # ------------------- ë–¨ë¦¼ ê°ì§€ ë¡œì§ -------------------
            # ğŸš¨ ì™¼ìª½ ì†ëª© ëŒ€ì‹  ì½”(NOSE) ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ë¡œ ë³€ê²½
            NOSE_INDEX = mp_pose.PoseLandmark.NOSE.value
            nose_landmark = results.pose_landmarks.landmark[NOSE_INDEX]
            
            # ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì‚¬ (visibilityê°€ ì¶©ë¶„íˆ ë†’ì•„ì•¼ í•¨)
            if nose_landmark.visibility > 0.8:
                
                # ëœë“œë§ˆí¬ ì¢Œí‘œ ì´ë ¥ ì—…ë°ì´íŠ¸ (Normalized X, Y ì‚¬ìš©)
                nose_history.append((nose_landmark.x, nose_landmark.y))
                
                # ì´ë ¥ ê´€ë¦¬ë¥¼ ìœ„í•´ ê°€ì¥ ì˜¤ë˜ëœ ì´ë ¥ ì œê±°
                if len(nose_history) > MAX_HISTORY_FRAMES:
                    nose_history.pop(0)

                # ì´ë ¥ì´ ì¶©ë¶„í•  ë•Œ ë–¨ë¦¼ ê³„ì‚°
                if len(nose_history) == MAX_HISTORY_FRAMES:
                    x_coords = [p[0] for p in nose_history]
                    y_coords = [p[1] for p in nose_history]
                    
                    current_tremor_score = calculate_tremor(x_coords, y_coords)
                    
                    if current_tremor_score > TREMOR_THRESHOLD:
                        tremor_status = f"(Tremor): {current_tremor_score:.5f}"
                        text_color = (0, 0, 255) # ë¹¨ê°„ìƒ‰
                    else:
                        tremor_status = f"(Stable): {current_tremor_score:.5f}"
                        text_color = (0, 255, 0) # ë…¹ìƒ‰
                
            else:
                tremor_status = "(Nose not visible)"
                text_color = (255, 255, 255) # í°ìƒ‰
        else:
            tremor_status = "No pose detected)"
            text_color = (255, 255, 255) # í°ìƒ‰

        
        if gaze.is_blinking():
            text = "Blinking"
        
        elif gaze.is_center():
            text = "Looking center"
            # ì¤‘ì•™ì„ ë³¼ ë•Œ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
            gaze_start_time = None
            is_gaze_outside_center = False
        
        elif gaze.is_right() or gaze.is_left():
            # ì™¼ìª½ ë˜ëŠ” ì˜¤ë¥¸ìª½ì„ ë³¼ ë•Œ (ì¤‘ì•™ì„ ë²—ì–´ë‚œ ê²½ìš°)
            
            if not is_gaze_outside_center:
                # ì¤‘ì•™ì„ ë²—ì–´ë‚œ ìƒíƒœê°€ 'ì•„ë‹ˆì—ˆë‹¤ë©´' (ìƒˆë¡œ ë²—ì–´ë‚¨) íƒ€ì´ë¨¸ ì‹œì‘
                gaze_start_time = current_time
                is_gaze_outside_center = True
                
            # ê²½ê³¼ ì‹œê°„ ê³„ì‚°
            if gaze_start_time is not None:
                elapsed_time = current_time - gaze_start_time
                
            if gaze.is_right():
                text = f"Looking right ({elapsed_time:.2f}s)"
            else: #
                text = f"Looking left ({elapsed_time:.2f}s)"
                
        else:
            # ê°ì§€ë˜ì§€ ì•Šê±°ë‚˜ ê¸°íƒ€ ìƒíƒœì¼ ê²½ìš°
            text = "Undetermined"
            gaze_start_time = None
            is_gaze_outside_center = False

        
        alert_text = ""
        alert_color = (147, 58, 31) # ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ=
        
        # ì¤‘ì•™ì„ ë²—ì–´ë‚œ ìƒíƒœì´ê³ , ê²½ê³¼ ì‹œê°„ì´ 3ì´ˆë¥¼ ë„˜ì—ˆì„ ë•Œ ê²½ê³  í™œì„±í™”
        if is_gaze_outside_center and elapsed_time >= ALERT_THRESHOLD:
            alert_text = ""
            alert_color = (0, 0, 255) # ë¹¨ê°„ìƒ‰ ê²½ê³ 
            # ì£¼ í…ìŠ¤íŠ¸ë„ ê²½ê³  ë©”ì‹œì§€ë¡œ ë®ì–´ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            text = f"Distracted: {elapsed_time:.2f}s"


        # ì‹œì„  ìƒíƒœ ë° ì‹œê°„ í‘œì‹œ
        cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, alert_color, 2)
        
        # 3ì´ˆ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ (ìˆì„ ê²½ìš°)
        if alert_text:
            cv2.putText(frame, alert_text, (90, 210), cv2.FONT_HERSHEY_DUPLEX, 1.0, (0, 0, 255), 2)


        # ë™ê³µ ì¢Œí‘œ í‘œì‹œ (ì›ë˜ ì½”ë“œ ìœ ì§€)
        cv2.putText(frame, "Tremor Status: " + tremor_status, (90, 95), cv2.FONT_HERSHEY_DUPLEX, 0.9, text_color, 1) # <--- ì¶”ê°€: ë–¨ë¦¼ ìƒíƒœ í‘œì‹œ
        left_pupil = gaze.pupil_left_coords()
        right_pupil = gaze.pupil_right_coords()
        # cv2.putText(frame, "Left pupil:  " + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)
        # cv2.putText(frame, "Right pupil: " + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)

        cv2.imshow("Demo", frame)

        if cv2.waitKey(1) == 27:
            break
   
webcam.release()
cv2.destroyAllWindows()