import tkinter as tk
from tkinter import Canvas, Button, PhotoImage
import os
from pathlib import Path
import time
import cv2 
from PIL import Image, ImageTk 
from .GazeTracking.example import AttentionMonitor
import google.generativeai as genai 

API_KEY = "AIzaSyBSuHxEGpxivX39ZPjy_cuI1jvDq5MkdyM"  

try:
    genai.configure(api_key=API_KEY)
    MODEL = genai.GenerativeModel('gemini-2.5-flash')
except Exception as e:
    print(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}. ì§ˆë¬¸ ìë™ ìƒì„± ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    MODEL = None


ASSETS_PATH = os.path.abspath("./UI/assets/mock_interview")

def relative_to_assets(path: str) -> Path:
    return Path(ASSETS_PATH) / Path(path)


class MockInterview(tk.Frame):
    def __init__(self, parent, controller):
        super().__init__(parent, bg="#FFFFFF")
        self.monitor = None
        self.controller = controller
        self.unfocustime = 0.0

        canvas = Canvas(self, bg="#FFFFFF", height=1080, width=1920)
        canvas.pack(fill="both", expand=True)

        self.bg_image = PhotoImage(file=relative_to_assets("image_1.png"))
        canvas.create_image(960, 540, image=self.bg_image)
          # ì´ë¯¸ì§€
        self.image1 = PhotoImage(file=relative_to_assets("bimage_l.png"))
        canvas.create_image(225,210, image=self.image1, anchor="nw")

        self.image2 = PhotoImage(file=relative_to_assets("bimage_r.png"))
        canvas.create_image(955,210, image=self.image2, anchor="nw")
            #ê°€ìƒë©´ì ‘ê´€ ì´ë¯¸ì§€ ìë¦¬
        self.image3 = PhotoImage(file=relative_to_assets("image_v.png"))
        canvas.create_image(735,266, image=self.image3, anchor="nw")
            #ì§ˆë¬¸ì°½
        self.image4 = PhotoImage(file=relative_to_assets("image_q.png"))
        canvas.create_image(419,761, image=self.image4, anchor="nw")
            #feedbackì°½
        self.image5 = PhotoImage(file=relative_to_assets("image_f.png"))
        canvas.create_image(1256,595, image=self.image5, anchor="nw")
            #ë©´ì ‘ì camìˆì–´ì•¼í•˜ëŠ” ìë¦¬
        self.image6 = PhotoImage(file=relative_to_assets("image_cam.png"))
        canvas.create_image(1310,266, image=self.image6, anchor="nw")

        self.image7 = PhotoImage(file=relative_to_assets("image_2.png"))
        canvas.create_image(230,147, image=self.image7, anchor="nw")
        
        # 6. ë©´ì ‘ì cam ìë¦¬ (1310, 266 - nw anchor)
        cam_x, cam_y = 1310, 266 
        
        # Tkinter Labelì„ ìƒì„±í•˜ê³  ìº”ë²„ìŠ¤ì— ë°°ì¹˜
        self.video_panel = tk.Label(self) 
        canvas.create_window(cam_x, cam_y, window=self.video_panel, anchor="nw")
        
        # ğŸŒŸ 1. ì§ˆë¬¸ í…ìŠ¤íŠ¸ ë³€ìˆ˜ ë° ë¼ë²¨ ì¶”ê°€ (ì§ˆë¬¸ì°½ 419, 761 - nw anchor ìœ„ì¹˜ í™œìš©)
        self.question_text = tk.StringVar(self)
        self.question_text.set("ë©´ì ‘ ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.") 
        
        q_x, q_y = 440, 780 
        q_width = 480 
        
        self.question_label = tk.Label(self, textvariable=self.question_text, 
                                       font=("AnekGurmukhi Light", 18), fg="#353C92", bg="white", 
                                       justify=tk.LEFT, anchor="nw", wraplength=q_width) # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì„¤ì •
        canvas.create_window(q_x, q_y, window=self.question_label, anchor="nw")
        
        # ğŸŒŸ 2. í”¼ë“œë°± í…ìŠ¤íŠ¸ ë ˆì´ë¸” ì¶”ê°€
        self.feedback_text = tk.StringVar(self)
        self.feedback_text.set("")
        
        self.feedback_label = tk.Label(self, textvariable=self.feedback_text, 
                                       font=("AnekGurmukhi Light", 18), fg="#353C92", bg="white", 
                                       justify=tk.LEFT, anchor="nw")
        canvas.create_window(1270, 640, window=self.feedback_label, anchor="nw")
        

        # ... (ì¢…ë£Œ ë²„íŠ¼, ì‹œì‘ ë²„íŠ¼, ì§„í–‰ì‹œê°„ ë¼ë²¨ - ìƒëµ) ...
        # ì¢…ë£Œ ë²„íŠ¼
        self.button_image_1 = PhotoImage(file=relative_to_assets("button_1.png"))
        button_1 = Button(self, image=self.button_image_1,
                          command=self.stop_camera_and_quit, 
                          borderwidth=0, relief="flat")
        canvas.create_window(1548, 865, window=button_1, anchor="nw")

        # ë©´ì ‘ì‹œì‘ ë²„íŠ¼
        self.button_image_2 = PhotoImage(file=relative_to_assets("button_2.png"))
        button_2 = Button(self, image=self.button_image_2,
                          command=self.start_interview,  
                          borderwidth=0, relief="flat")
        canvas.create_window(455, 563, window=button_2, anchor="nw")
        
        # ì§„í–‰ì‹œê°„ ë¼ë²¨
        canvas.create_text(447, 452, anchor="nw", text="ì§„í–‰ì‹œê°„", fill="#000000", font=("AnekGurmukhi Light", 22))
        self.timer_label = tk.Label(self, text="60", font=("Arial", 24), bg="#FFFFFF")
        canvas.create_window(445, 500, window=self.timer_label, anchor="nw")
        
        # ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ ë£¨í”„ë¥¼ ìœ„í•œ ë³€ìˆ˜
        self.delay = 30 
        self.camera_update_id = None
        self.is_interview_running = False



    def _fetch_gemini_question(self):
        if not MODEL:
            return "Gemini API ì„¤ì •ì— ë¬¸ì œê°€ ìˆì–´ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            question = "í•œêµ­ì¸ ë©´ì ‘ê´€ìœ¼ë¡œ ëœë¤ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ë‚´ë´ ì§ˆë¬¸ë§Œ ê°„ê²°í•˜ê²Œ ë‹µí•´ì¤˜"
            # ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì œê±° í›„ ë°˜í™˜
            response = MODEL.generate_content(question)
            return response.text.strip()
            
        except Exception as e:
            return f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


    def start_interview(self):
        """ë©´ì ‘ ì‹œì‘ ì‹œ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ê³  íƒ€ì´ë¨¸ ë° ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        if not self.is_interview_running:
            self.is_interview_running = True
            
            #ë©´ì ‘ ì‹œì‘ ì‹œ Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§ˆë¬¸ì„ ê°€ì ¸ì™€ì„œ ì—…ë°ì´íŠ¸
            question = self._fetch_gemini_question()
            self.question_text.set(question)
            
            self.start_timer()
            self.start_camera()
            self.update_camera() 

    def stop_camera_and_quit(self):
        """ì¹´ë©”ë¼ë¥¼ í•´ì œí•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        if self.camera_update_id:
            self.after_cancel(self.camera_update_id) 
        if not self.monitor.__del__:
            self.monitor.__del__() 
        
        print(self.unfocustime)
        print("ì¹´ë©”ë¼ ë° ë©´ì ‘ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.controller.show_frame("WaitGame")
        
    def start_timer(self):
        self.remaining_time = 60 #
        self.update_timer()

    def update_timer(self):
        if self.remaining_time > 0:
            self.timer_label.config(text=str(self.remaining_time))
            self.remaining_time -= 1
            self.after(1000, self.update_timer)
        else:
             self.is_interview_running = False
             self.monitor.__del__()
             self.question_text.set("ë©´ì ‘ ì¢…ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    def start_camera(self):
        self.monitor = AttentionMonitor(camera_index=4)

    def update_camera(self):
        ret, frame = self.monitor.get_frame()
        if ret:
            annotated_frame, results = self.monitor.process_frame()
            
            if annotated_frame is not None:
                cv2image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGBA)
                
                current_image = Image.fromarray(cv2image)
                
                cam_width, cam_height = 300, 300 
                resized_image = current_image.resize((cam_width, cam_height))
                self.photo = ImageTk.PhotoImage(image=resized_image)
                self.video_panel.config(image=self.photo)
                self.video_panel.image = self.photo 
                feedback, self.unfocustime = self._generate_feedback_text(results,self.unfocustime)
                self.feedback_text.set(feedback)
                
            
        self.camera_update_id = self.after(self.delay, self.update_camera)

    def _generate_feedback_text(self, results,unfocustime):
        feedback = []
        # 1. ì‹œì„  í”¼ë“œë°±
        gaze_text = results.get("gaze_text", "None")
        gaze_time = results.get("gaze_elapsed_time", 0.0)
        gaze_unfoucs = results.get("distraction_time")

        if "distraction" in gaze_text:
            feedback.append(f"ì‹œì„  ìƒíƒœ : ëˆˆì„ ë§ì¶”ì£¼ì‹­ì‹œì˜¤")
        elif "focus on right" in gaze_text or "focus on left" in gaze_text:
            feedback.append(f"ì‹œì„  ì´íƒˆ ê°ì§€: ì¤‘ì•™ì„ ë²—ì–´ë‚œ ì§€ {gaze_time:.2f}ì´ˆ ê²½ê³¼.") 
        else:
            feedback.append(f"ì‹œì„  ìƒíƒœ: {gaze_text}")
        unfocustime = max(gaze_unfoucs,unfocustime)
        # 2. ë–¨ë¦¼ í”¼ë“œë°±
        tremor_status = results.get("tremor_status", "(Stable)")
        
        if "Tremor" in tremor_status:
            feedback.append("ì‹ ì²´ ìƒíƒœ : ë¶ˆì•ˆì •  ")
        elif "Stable" in tremor_status:
            feedback.append(f" ì‹ ì²´ ìƒíƒœ: ì•ˆì •ì ì…ë‹ˆë‹¤.")
        else:
            feedback.append(f" ì‹ ì²´ ìƒíƒœ: ê°ì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
            
        return "\n".join(feedback),unfocustime

