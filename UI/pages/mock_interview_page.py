from tkinter import *
from PIL import Image, ImageTk
import os
from pathlib import Path
import time
import cv2 
from PIL import Image, ImageTk 
from .GazeTracking.example import AttentionMonitor
import google.generativeai as genai 
import random

# API_KEY = "AIzaSyBSuHxEGpxivX39ZPjy_cuI1jvDq5MkdyM"  

# try:
#     genai.configure(api_key=API_KEY)
#     MODEL = genai.GenerativeModel('gemini-2.5-flash')
# except Exception as e:
#     print(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}. ì§ˆë¬¸ ìë™ ìƒì„± ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
#     MODEL = None

ASSETS_PATH = os.path.abspath("./UI/assets")
WEIGHT_CENTER = 1920 //2
HEIGHT_CENTER = 1080 // 2
MAINCOLOR = "#703BA2"
# SUBCOLOR = 
qustion_list = ["5ë…„ í›„ ë³¸ì¸ì˜ ì»¤ë¦¬ì–´ ëª©í‘œì™€ ê·¸ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ê³„íšì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?","ì§€ì›í•˜ì‹  ì§ë¬´ì™€ ê´€ë ¨í•˜ì—¬ ë³¸ì¸ì´ ê°€ì§„ ê°€ì¥ í° ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì´ë©°, ì•½ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ê³  ìˆìŠµë‹ˆê¹Œ?","1ë¶„ ë™ì•ˆ ë³¸ì¸ ì†Œê°œë¥¼ í•´ì£¼ì‹­ì‹œì˜¤.","ì‚´ë©´ì„œ ê°€ì¥ í° ì„±ê³µ ê²½í—˜ê³¼ ì‹¤íŒ¨ ê²½í—˜ì„ ê°ê° ì´ì•¼ê¸°í•´ ì£¼ì‹­ì‹œì˜¤.","ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ë°©ë²•ì´ë‚˜ ë³¸ì¸ë§Œì˜ ì›ë™ë ¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?",
                "ì…ì‚¬ í›„ ê°€ì¥ ë¨¼ì € í•˜ê³  ì‹¶ì€ ì¼ì€ ë¬´ì—‡ì´ë©°, íšŒì‚¬ì— ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆê¹Œ?"]


def relative_to_assets(path: str) -> Path:
    return Path(ASSETS_PATH) / Path(path)

class MockInterview(Frame):
    def __init__(self, parent, controller):
        super().__init__(parent, bg="#FFFFFF")
        self.monitor = None
        self.controller = controller
        self.unfocustime = 0.0
        self.tremor_time = 0.0
        canvas = Canvas(self, bg="#FFFFFF", height=1080, width=1920)
        canvas.pack(fill="both", expand=True)

        # ë°°ê²½ ì´ë¯¸ì§€
        self.bg_image = ImageTk.PhotoImage(Image.open(relative_to_assets("img_background.png")))
        canvas.create_image(WEIGHT_CENTER, 540, image=self.bg_image)
        self.win_image = ImageTk.PhotoImage(Image.open(relative_to_assets("img_win.png")))
        canvas.create_image(WEIGHT_CENTER, 550.0, image=self.win_image)

        # ìƒë‹¨ íƒ€ì´í‹€
        canvas.create_text(
            WEIGHT_CENTER,
            160,
            justify="center",
            anchor="center",
            text="ê°€ìƒ ë©´ì ‘",
            fill='#FFFFFF',
            font=("Malgun Gothic", 30)
        )

        # ìƒë‹¨ íƒ€ì´í‹€ - ì´ì „ BUTTON
        self.btn_previous = ImageTk.PhotoImage(Image.open(relative_to_assets("button/btn_previous.png")))
        btn_previous = Button(self,
                            image=self.btn_previous,
                            borderwidth=0,
                            relief="flat",
                            command=lambda: controller.show_frame("FirstPage"))
        canvas.create_window(1600, 162, window=btn_previous, anchor="center")
        

          # ì´ë¯¸ì§€
        # self.image1 = PhotoImage(file=relative_to_assets("bimage_l.png"))
        # canvas.create_image(225,210, image=self.image1, anchor="nw")

        # self.image2 = PhotoImage(file=relative_to_assets("bimage_r.png"))
        # canvas.create_image(955,210, image=self.image2, anchor="nw")
            #ê°€ìƒë©´ì ‘ê´€ ì´ë¯¸ì§€ ìë¦¬
        self.image3 = PhotoImage(file=relative_to_assets("mock_interview/image_v.png"))
        canvas.create_image(735,266, image=self.image3, anchor="nw")
            #ì§ˆë¬¸ì°½
        self.image4 = PhotoImage(file=relative_to_assets("mock_interview/image_q.png"))
        canvas.create_image(419,761, image=self.image4, anchor="nw")
            #feedbackì°½
        self.image5 = PhotoImage(file=relative_to_assets("mock_interview/image_f.png"))
        canvas.create_image(1256,595, image=self.image5, anchor="nw")
            #ë©´ì ‘ì camìˆì–´ì•¼í•˜ëŠ” ìë¦¬
        self.image6 = PhotoImage(file=relative_to_assets("mock_interview/image_cam.png"))
        canvas.create_image(1310,266, image=self.image6, anchor="nw")

        
        # 6. ë©´ì ‘ì cam ìë¦¬ (1310, 266 - nw anchor)
        cam_x, cam_y = 1310, 266 
        
        # Tkinter Labelì„ ìƒì„±í•˜ê³  ìº”ë²„ìŠ¤ì— ë°°ì¹˜
        self.video_panel = Label(self) 
        canvas.create_window(cam_x, cam_y, window=self.video_panel, anchor="nw")
        
        # ğŸŒŸ 1. ì§ˆë¬¸ í…ìŠ¤íŠ¸ ë³€ìˆ˜ ë° ë¼ë²¨ ì¶”ê°€ (ì§ˆë¬¸ì°½ 419, 761 - nw anchor ìœ„ì¹˜ í™œìš©)
        self.question_text = StringVar(self)
        self.question_text.set("ë©´ì ‘ ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.") 
        
        q_x, q_y = 440, 780 
        q_width = 480 
        
        self.question_label = Label(self, textvariable=self.question_text, 
                                       font=("AnekGurmukhi Light", 18), fg="#353C92", bg="white", 
                                       justify=LEFT, anchor="nw", wraplength=q_width) # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì„¤ì •
        canvas.create_window(q_x, q_y, window=self.question_label, anchor="nw")
        
        # ğŸŒŸ 2. í”¼ë“œë°± í…ìŠ¤íŠ¸ ë ˆì´ë¸” ì¶”ê°€
        self.feedback_text = StringVar(self)
        self.feedback_text.set("")
        
        self.feedback_label = Label(self, textvariable=self.feedback_text, 
                                       font=("AnekGurmukhi Light", 18), fg="#353C92", bg="white", 
                                       justify=LEFT, anchor="nw")
        canvas.create_window(1270, 640, window=self.feedback_label, anchor="nw")
        
        # ì¢…ë£Œ ë²„íŠ¼
        self.btn_end = PhotoImage(file=relative_to_assets("button/btn_blue.png"))
        button_1 = Button(self, image= self.btn_end, text="ì¢…ë£Œ", font=("AnekGurmukhi Bold", 16), compound="center",
                          command= lambda: self.stop_camera_and_quit(), 
                          borderwidth=0, relief="flat")
        canvas.create_window(1560, 860, window=button_1, anchor="nw")

        # ë©´ì ‘ì‹œì‘ ë²„íŠ¼
        self.btn_interview_start= PhotoImage(file=relative_to_assets("button/btn_interview_start.png"))
        button_2 = Button(self, image=self.btn_interview_start,
                          command=lambda: self.start_interview(),  
                          borderwidth=0, relief="flat")
        canvas.create_window(455, 563, window=button_2, anchor="nw")
        
        # ì§„í–‰ì‹œê°„ ë¼ë²¨
        canvas.create_text(447, 452, anchor="nw", text="ì§„í–‰ì‹œê°„", fill="#000000", font=("AnekGurmukhi Light", 22))
        self.timer_label = Label(self, text="60", font=("Arial", 24), bg="#FFFFFF")
        canvas.create_window(445, 500, window=self.timer_label, anchor="nw")
        
        # ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ ë£¨í”„ë¥¼ ìœ„í•œ ë³€ìˆ˜
        self.delay = 30 
        self.camera_update_id = None
        self.is_interview_running = False



    # def _fetch_gemini_question(self):
    #     if not MODEL:
    #         return "Gemini API ì„¤ì •ì— ë¬¸ì œê°€ ìˆì–´ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    #     try:
    #         question = "í•œêµ­ì¸ ë©´ì ‘ê´€ìœ¼ë¡œ ëœë¤ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ë‚´ë´ ì§ˆë¬¸ë§Œ ê°„ê²°í•˜ê²Œ ë‹µí•´ì¤˜"
    #         # ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì œê±° í›„ ë°˜í™˜
    #         response = MODEL.generate_content(question)
    #         return response.text.strip()
            
    #     except Exception as e:
    #         return f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


    def start_interview(self):
        """ë©´ì ‘ ì‹œì‘ ì‹œ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ê³  íƒ€ì´ë¨¸ ë° ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        if not self.is_interview_running:
            self.is_interview_running = True
            
            #ë©´ì ‘ ì‹œì‘ ì‹œ Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì§ˆë¬¸ì„ ê°€ì ¸ì™€ì„œ ì—…ë°ì´íŠ¸
            question = random.sample(qustion_list, k=1)
            self.question_text.set(question)
            
            self.start_timer()
            self.start_camera()
            self.update_camera() 

    def stop_camera_and_quit(self):
        """ì¹´ë©”ë¼ë¥¼ í•´ì œí•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        if self.camera_update_id:
            self.after_cancel(self.camera_update_id) 
        if not self.monitor.__del__:
            self.monitor.__del__() 
        
        print(self.unfocustime)
        print(self.tremor_time)
        print("ì¹´ë©”ë¼ ë° ë©´ì ‘ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.controller.show_frame("WaitGame")
        
    def start_timer(self):
        self.remaining_time = 60 #
        self.update_timer()

    def update_timer(self):
        if self.remaining_time > 0:
            self.timer_label.config(text=str(self.remaining_time))
            self.remaining_time -= 1
            self.after(1000, self.update_timer)
        else:
             self.is_interview_running = False
             self.monitor.__del__()
             self.question_text.set("ë©´ì ‘ ì¢…ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    def start_camera(self):
        self.monitor = AttentionMonitor(camera_index=4)

    def update_camera(self):
        ret, frame = self.monitor.get_frame()
        if ret:
            annotated_frame, results = self.monitor.process_frame()
            
            if annotated_frame is not None:
                cv2image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGBA)
                
                current_image = Image.fromarray(cv2image)
                
                cam_width, cam_height = 300, 300 
                resized_image = current_image.resize((cam_width, cam_height))
                self.photo = ImageTk.PhotoImage(image=resized_image)
                self.video_panel.config(image=self.photo)
                self.video_panel.image = self.photo 
                feedback, self.unfocustime , self.tremor_time = self._generate_feedback_text(results,self.unfocustime,self.tremor_time)
                self.feedback_text.set(feedback)
                
            
        self.camera_update_id = self.after(self.delay, self.update_camera)

    def _generate_feedback_text(self, results,unfocustime,tremor_time):
        feedback = []
        # 1. ì‹œì„  í”¼ë“œë°±
        gaze_text = results.get("gaze_text", "None")
        gaze_time = results.get("gaze_elapsed_time", 0.0)
        gaze_unfoucs = results.get("distraction_time")
        tremor_time1 = results.get("tremor_time")
        
        if "distraction" in gaze_text:
            feedback.append(f"ì‹œì„  ìƒíƒœ : ëˆˆì„ ë§ì¶”ì£¼ì‹­ì‹œì˜¤")
        elif "focus on right" in gaze_text or "focus on left" in gaze_text:
            feedback.append(f"ì‹œì„  ì´íƒˆ ê°ì§€: ì¤‘ì•™ì„ ë²—ì–´ë‚œ ì§€ {gaze_time:.2f}ì´ˆ ê²½ê³¼.") 
        else:
            feedback.append(f"ì‹œì„  ìƒíƒœ: {gaze_text}")
        unfocustime = max(gaze_unfoucs,unfocustime)
        # 2. ë–¨ë¦¼ í”¼ë“œë°±
        tremor_status = results.get("tremor_status", "(Stable)")
        
        if "Tremor" in tremor_status:
            feedback.append("ì‹ ì²´ ìƒíƒœ : ë¶ˆì•ˆì •  ")
        elif "Stable" in tremor_status:
            feedback.append(f" ì‹ ì²´ ìƒíƒœ: ì•ˆì •ì ì…ë‹ˆë‹¤.")
        else:
            feedback.append(f" ì‹ ì²´ ìƒíƒœ: ê°ì§€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
        tremor_time1 = max(tremor_time,tremor_time1)
        return "\n".join(feedback),unfocustime,tremor_time1
    
    @property
    def get_parameter(self):
        return self.unfocustime, self.tremor_time
